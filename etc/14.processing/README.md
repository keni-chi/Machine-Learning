# processing

変数の標準化(オートスケーリング)
    テストデータを予測するとき
        トレーニングデータの平均値・標準偏差を用いてテストデータのオートスケーリングをする。
        トレーニングデータとテストデータとを合わせた平均値・標準偏差でオートスケーリングすると、テストデータの目的変数の値が事前にわかっていることになってしまうので、目的変数の値がわかっている (と仮定した) トレーニングデータの平均値・標準偏差でオートスケーリングする。
    トレーニングデータでのクロスバリデーション
        モデル構築前のハイパーパラメータを決めるだけなので、クロスバリデーションで分割した、すべてのグループにおいて目的変数の値がわかっていると仮定しても問題ない。
    ハイパーパラメータを決める時もトレーニングデータでオートスケーリングした方が良さそうに思えるが、以下のデメリットがある。
        分割することでサンプルが少なくなり、それによりトレーニングデータで標準偏差が 0 の説明変数が出たときに、それを削除する必要がある。即ち、分割して得られたトレーニングデータごとに説明変数のセットが変わることになってしまう。

対数変換
    ヒストグラム作成→右に裾野が広がっている→skewness（歪度）→skewnessが大きい値となっていて分布が歪んでいる→対数変換をして分布を修正
    X,ｙともに対数変換し、単回帰を行う。
    正規分布に従わせるための対数変換（対数変換によりさらに歪度が増大し、正規分布から離れてしまうこともあるので注意）
    外れ値が含まれるデータの分散を小さくするための対数変換（分散が増大してしまうこともあるので、注意）
