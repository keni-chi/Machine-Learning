# 全般


上の実測値 vs. 推定値プロット
    モデルの適用範囲
        トレーニングデータに類似したサンプル (今回は化合物) がない
        モデルの適用範囲・モデルの適用領域 (Applicability Domain, AD) についてです。AD は回帰モデル・クラス分類モデルが本来の性能を発揮できるデータ領域のこと。
            凸包
            トレーニングデータの中心からの距離
            データ密度（SVM、K近傍）
            アンサンブル学習での分散がなければ適用

    回帰モデルが目的変数を説明できるほど学習できていない


    現状の記述子では目的変数を説明できない



    目的変数の実測値が間違えている

アンサンブル学習
    概要
        複数の異なるモデルを構築して、推定するときはそれらのモデルの推定結果を統合するのがアンサンブル学習。
    ランダムフォレスト
        例として、決定木 (Decision Tree, DT) をアンサンブル学習すると、ランダムフォレスト (Random Forests, RF) になる。
        ランダムフォレストでは、サンプルをブートストラップ法で選び、同時に説明変数をジャックナイフ法で選ぶことで、サブデータセットを作成し、サブモデルとしての決定木をつくっている。
    異なるモデルの構築方法
        サンプルや説明変数 (記述子・特徴量・入力変数) を変えてモデルを作る。
            重複を許してサンプルを選ぶ方法：ブートストラップ法 (bootstrap resampling or bootstrapping)。bagging (バギング) 。
            重複を許さずサンプルを選ぶ方法：ジャックナイフ法 (Jackknife resampling or jackknifing)
        サンプルからではなく、説明変数から選ぶときは、同じ変数があっても無意味なので、ジャックナイフ法を使う必要がある。
    メリット
        外れ値やノイズに対してロバストな推定ができる
            １つのモデルの場合、外れ値やノイズの影響を受けたモデルとなり、新しいサンプルの推定のとき、推定を失敗することもある。アンサンブル学習により、リサンプリングしてたくさんモデルを作ることで、外れ値の影響を受けたサブモデルだけでなく、(あまり)受けていないサブモデルもできる。最後に多数決や平均値・中央値を求めることで、外れ値の影響を減らせる。ノイズについても、推定値が平均化されることでばらつきが軽減できる。
        推定値のバイアスが減る
            Adaptive Boosting。通常のバギングではなく、これまでのサブモデルで推定に失敗したサンプルほど高確率で選ばれるようにする。
        推定値の不確かさ (モデルの適用範囲・適用領域) を考慮できる。
            分類
                多数決だけでなく、その内訳まで確認し、不確かさを考慮。
            回帰
                推定値の標準偏差を指標にする。推定値の標準偏差、つまり推定値のばらつきが小さいときは、平均値・中央値は推定値として確からしいだろう、逆に大きいときはその分平均値や中央値から実測値がズレる可能性もあるだろう、と考える。
    デメリット
        計算時間がかかる。サブモデルをたくさん構築し、各サブモデルでハイパーパラメータを最適化しなければならない。







# 参考
[データ解析に関するいろいろな手法・考え方・注意点のまとめ](https://datachemeng.com/summarydataanalysis/)  

