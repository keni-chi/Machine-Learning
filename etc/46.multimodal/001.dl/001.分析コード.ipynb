{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9479f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "from sklearn import model_selection\n",
    "from sklearn import preprocessing\n",
    "import IPython.display as ipd\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import re\n",
    "import unicodedata\n",
    "import librosa\n",
    "import librosa.display\n",
    "from keras import utils "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4d6439",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578bf40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define directories\n",
    "base_dir = \".\\\\\"\n",
    "\n",
    "oc256_dir = \".\\\\256_ObjectCategories\"\n",
    "oc256_dirs = [os.path.join(oc256_dir, x) for x in os.listdir(oc256_dir)]\n",
    "oc256_files = [[os.path.join(x,y) for y in os.listdir(x)] for x in oc256_dirs]\n",
    "# make a dict of label num to category name\n",
    "oc_class_dict = {int(x.split(\"\\\\\")[-1].split(\".\")[0]): x.split(\"\\\\\")[-1].split(\".\")[1] for x in oc256_dirs}\n",
    "\n",
    "# dict of label to category of the image dataset\n",
    "print(oc_class_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180a0349",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 画像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee292f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert2dgray_to_3dgray(img_array):\n",
    "    return np.array([[[y,y,y] for y in x] for x in img_array])\n",
    "\n",
    "def resize_image_array(img_array, image_size=(299, 299)):\n",
    "    if img_array is None:\n",
    "        return None\n",
    "    return cv2.resize(img_array, image_size)\n",
    "\n",
    "# save image data in npz\n",
    "def save_np_256_oc_data(x, data_type=\"train\"):\n",
    "    data_dir = \"256_\" + data_type\n",
    "    if not os.path.exists(data_dir):\n",
    "        os.makedirs(data_dir)\n",
    "    for _,c in enumerate(x):\n",
    "        for _,f in enumerate(c):\n",
    "            print(f)\n",
    "            image_name = f.split(\"\\\\\")[3].split(\".\")[0]\n",
    "            image_path = os.path.join(data_dir, image_name)\n",
    "            if not os.path.exists(image_path):\n",
    "                y = f.split(\"\\\\\")[2].split(\".\")[0]\n",
    "                img = Image.open(os.path.join(f))\n",
    "                img = np.asarray(img)\n",
    "                if len(img.shape) == 2:\n",
    "                    img = convert2dgray_to_3dgray(img)\n",
    "                img = resize_image_array(img, image_size=(299, 299))\n",
    "                np.savez(image_path, img=img, y=y)\n",
    "\n",
    "save_np_256_oc_data(oc256_files,  data_type=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4157cde2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb229821",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 音声"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4a88a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "esc_dir = os.path.join(base_dir, \"ESC-50-master\")\n",
    "meta_file = os.path.join(esc_dir, \"meta/esc50.csv\")\n",
    "audio_dir = os.path.join(esc_dir, \"audio/\")\n",
    "\n",
    "# load metadata\n",
    "meta_data = pd.read_csv(meta_file)\n",
    "\n",
    "# get data size\n",
    "data_size = meta_data.shape\n",
    "print(data_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a54dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dict of label num to category name\n",
    "esc_class_dict = {}\n",
    "for i in range(data_size[0]):\n",
    "    if meta_data.loc[i,\"target\"] not in esc_class_dict.keys():\n",
    "        esc_class_dict[meta_data.loc[i,\"target\"]] = meta_data.loc[i,\"category\"]\n",
    "\n",
    "# load a wave data\n",
    "def load_wave_data(audio_dir, file_name):\n",
    "    file_path = os.path.join(audio_dir, file_name)\n",
    "    x, fs = librosa.load(file_path, sr=44100)\n",
    "    return x,fs\n",
    "\n",
    "# change wave data to mel-stft\n",
    "def calculate_melsp(x, n_fft=1024, hop_length=128):\n",
    "    stft = np.abs(librosa.stft(x, n_fft=n_fft, hop_length=hop_length))**2\n",
    "    log_stft = librosa.power_to_db(stft)\n",
    "    melsp = librosa.feature.melspectrogram(S=log_stft,n_mels=128)\n",
    "    return melsp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b23bd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display wave in plots\n",
    "def show_wave(x):\n",
    "    plt.plot(x)\n",
    "    plt.show()\n",
    "\n",
    "# display wave in heatmap\n",
    "def show_melsp(melsp, fs):\n",
    "    librosa.display.specshow(melsp, sr=fs)\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "\n",
    "# example data\n",
    "_x, _fs = load_wave_data(audio_dir, meta_data.loc[0,\"filename\"])\n",
    "_melsp = calculate_melsp(_x)\n",
    "print(\"wave size:{0}\\nmelsp size:{1}\\nsamping rate:{2}\".format(_x.shape, _melsp.shape, _fs))\n",
    "show_wave(_x)\n",
    "show_melsp(_melsp, _fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6e61ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict of label to category of the sound dataset\n",
    "print(esc_class_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45040ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d078b8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import difflib\n",
    "\n",
    "# look for label that spells similar from the image and sound to make combinations\n",
    "close_values = []\n",
    "for ok,ov in oc_class_dict.items():\n",
    "    for ek,ev in esc_class_dict.items():\n",
    "        r = difflib.SequenceMatcher(None, ov, ev).ratio()\n",
    "        if r > 0.6: # category names as close as 60% is considered close\n",
    "            close_values.append([ok,ov,ek,ev,r])\n",
    "for l in close_values:\n",
    "    print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927c099a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f35e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_oc_esc = {\n",
    "    58:30, #[58, 'doorknob', 30, 'door_wood_knock', 0.6086956521739131]\n",
    "    102:40, #[102, 'helicopter-101', 40, 'helicopter', 0.8333333333333334]\n",
    "    239:35, #[239, 'washing-machine', 35, 'washing_machine', 0.9333333333333333] \n",
    "    245:16, #[245, 'windmill', 16, 'wind', 0.6666666666666666]\n",
    "    113:14, #[113, 'hummingbird', 14, 'chirping_birds', 0.64]\n",
    "    170:10, #[170, 'rainbow', 10, 'rain', 0.7272727272727273]\n",
    "    89:1, #[89, 'goose', 1, 'rooster', 0.6666666666666666]\n",
    "    73:48, #[73, 'fireworks', 48, 'fireworks', 1.0]\n",
    "    251:47, #[251, 'airplanes-101', 47, 'airplane', 0.7619047619047619]\n",
    "    56:0, #[56, 'dog', 0, 'dog', 1.0]\n",
    "    80:4 #[80, 'frog', 4, 'frog', 1.0]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268afa15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict for Caltech image target label and category name\n",
    "chosen_kv = {\n",
    "    58:'door', \n",
    "    102:'helicopter'\n",
    "    #239:'washingmachine',\n",
    "    #245:'wind',\n",
    "    #113:'hummingbird',\n",
    "    #170:'rain',\n",
    "    #89:'chicken',\n",
    "    #73:'fireworks',\n",
    "    #251:'airplane',\n",
    "    #56:'dog',\n",
    "    #80:'frog'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31534f4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8391de7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# テキスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9024eb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# texts are downloaded from Wikipedia\n",
    "textdir = \".\\\\wiki\"\n",
    "textfiles = [os.path.join(textdir, x) for x in os.listdir(textdir)]\n",
    "print(textfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc59b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dict with key as label and value as a list of sentences\n",
    "oc_txt_dict = {}\n",
    "for t in textfiles:\n",
    "    with open(t,'r', encoding='utf-8') as f:\n",
    "        print('a')\n",
    "        print(t)\n",
    "        k = int(t.split(\"\\\\\")[-1].split(\"_\")[0])\n",
    "        print(k)\n",
    "        d = f.readlines()\n",
    "        d = [x.replace(\"\\n\",\"\") for x in d]\n",
    "        print(d)\n",
    "        oc_txt_dict[k] = d\n",
    "        \n",
    "        \n",
    "print(oc_txt_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1cc32a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "72e6ef73",
   "metadata": {},
   "source": [
    "## 2. データセットを組み合わせる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81901dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a compound of image, sound and text for each targets\n",
    "esc_np_dir = \".\\\\ESC-50-master\\\\audio\\\\\"\n",
    "oc_np_dir = \".\\\\256_all\"\n",
    "\n",
    "texts_data_train = []\n",
    "img_data_train = []\n",
    "snd_data_train = []\n",
    "target_train = []\n",
    "category_train = []\n",
    "\n",
    "texts_data_test = []\n",
    "img_data_test = []\n",
    "snd_data_test = []\n",
    "target_test = []\n",
    "category_test = []\n",
    "t = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20881fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ok,c in chosen_kv.items():\n",
    "    #print(os.listdir(oc_np_dir))\n",
    "    print(ok)\n",
    "    oc_list = [os.path.join(oc_np_dir, x) for x in os.listdir(oc_np_dir) if int(x.split(\"_\")[0])==ok]\n",
    "    print(oc_list)\n",
    "    esc_list = [os.path.join(esc_np_dir, x) for x in os.listdir(esc_np_dir) if int(x.split(\"-\")[-1].split(\".\")[0])==chosen_oc_esc[ok]]\n",
    "    print(esc_list)\n",
    "\n",
    "    # choose test dataset\n",
    "    print(oc_txt_dict[ok])\n",
    "    print(range(len(oc_txt_dict[ok])))\n",
    "    print(random.sample(range(len(oc_txt_dict[ok])), 8))\n",
    "    test_text = random.sample(range(len(oc_txt_dict[ok])), 8) # list of test text index\n",
    "    test_img = random.sample(range(len(oc_list)), 8) # list of test image index\n",
    "    test_snd = random.sample(range(len(esc_list)), 8) # list of test sound index\n",
    "    # make compound test data\n",
    "    target_test.extend([t]*8)\n",
    "    texts_data_test.extend([v for i,v in enumerate(oc_txt_dict[ok]) if i in test_text])\n",
    "    img_data_test.extend([v for i,v in enumerate(oc_list) if i in test_img])\n",
    "    snd_data_test.extend([v for i,v in enumerate(esc_list) if i in test_snd])\n",
    "    category_test.extend([c]*8)\n",
    "\n",
    "    # make test data with one element missing\n",
    "    missing = random.choices([0,1,2], k=8)\n",
    "    for _,p in enumerate(missing):\n",
    "        tt = [0] if p==0 else [oc_txt_dict[ok][random.choice(test_text)]]\n",
    "        it = [None] if p==1 else [oc_list[random.choice(test_img)]]\n",
    "        st = [None] if p==2 else [esc_list[random.choice(test_snd)]]\n",
    "        texts_data_test.extend(tt)\n",
    "        img_data_test.extend(it)\n",
    "        snd_data_test.extend(st)\n",
    "        target_test.extend([t])\n",
    "        category_test.extend([c])\n",
    "\n",
    "    # make test data with two elements missing\n",
    "    have = random.choices([0,1,2], k=8)\n",
    "    for _,p in enumerate(have):\n",
    "        tt = [oc_txt_dict[ok][random.choice(test_text)]] if p==0 else [0]\n",
    "        it = [oc_list[random.choice(test_img)]] if p==1 else [None]\n",
    "        st = [esc_list[random.choice(test_snd)]] if p==2 else [None]\n",
    "        texts_data_test.extend(tt)\n",
    "        img_data_test.extend(it)\n",
    "        snd_data_test.extend(st)\n",
    "        target_test.extend([t])\n",
    "        category_test.extend([c])\n",
    "\n",
    "\n",
    "    # make compound dataset for training\n",
    "    train_text = [v for i,v in enumerate(oc_txt_dict[ok]) if i not in test_text] # list of training text\n",
    "    train_img = [v for i,v in enumerate(oc_list) if i not in test_img] # list of training img\n",
    "    train_snd = [v for i,v in enumerate(esc_list) if i not in test_snd] # list of training sound\n",
    "    # allowing some duplicates\n",
    "    target_train.extend([t]*60)\n",
    "    texts_data_train.extend(random.choices(train_text, k=60))\n",
    "    img_data_train.extend(random.choices(train_img, k=60))\n",
    "    snd_data_train.extend(random.choices(train_snd, k=60))\n",
    "    category_train.extend([c]*60)\n",
    "\n",
    "    # make train data with one element missing\n",
    "    missing = random.choices([0,1,2], k=60)\n",
    "    for _,p in enumerate(missing):\n",
    "        tt = [0] if p==0 else [random.choice(train_text)]\n",
    "        it = [None] if p==1 else [random.choice(train_img)]\n",
    "        st = [None] if p==2 else [random.choice(train_snd)]\n",
    "        texts_data_train.extend(tt)\n",
    "        img_data_train.extend(it)\n",
    "        snd_data_train.extend(st)\n",
    "        target_train.extend([t])\n",
    "        category_train.extend([c])\n",
    "\n",
    "    # make train data with two elements missing\n",
    "    have = random.choices([0,1,2], k=60)\n",
    "    for _,p in enumerate(have):\n",
    "        tt = [random.choice(train_text)] if p==0 else [0]\n",
    "        it = [random.choice(train_img)] if p==1 else [None]\n",
    "        st = [random.choice(train_snd)] if p==2 else [None]\n",
    "        texts_data_train.extend(tt)\n",
    "        img_data_train.extend(it)\n",
    "        snd_data_train.extend(st)\n",
    "        target_train.extend([t])\n",
    "        category_train.extend([c])\n",
    "\n",
    "    t+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ef5d12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7c654a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make pandas dataframe for better looking\n",
    "dataset_train = pd.DataFrame({\n",
    "    \"category\":category_train,\n",
    "    \"target\":target_train,\n",
    "    \"img\":img_data_train,\n",
    "    \"snd\":snd_data_train,\n",
    "    \"text\":texts_data_train\n",
    "})\n",
    "dataset_train.to_csv(\".\\\\dataset_train.csv\")\n",
    "dataset_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639f23b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e689171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make pandas dataframe for better looking\n",
    "dataset_test = pd.DataFrame({\n",
    "    \"category\":category_test,\n",
    "    \"target\":target_test,\n",
    "    \"img\":img_data_test,\n",
    "    \"snd\":snd_data_test,\n",
    "    \"text\":texts_data_test\n",
    "})\n",
    "dataset_test.to_csv(\".\\\\dataset_test.csv\")\n",
    "dataset_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d379739",
   "metadata": {},
   "source": [
    "## 3. データの前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cd6018",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_img_path = dataset_train[\"img\"].values\n",
    "x_test_img_path = dataset_test[\"img\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03755f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training images\n",
    "x_train_img = np.zeros((len(x_train_img_path), 299,299,3))\n",
    "for i,p in enumerate(x_train_img_path):\n",
    "    if p is not None:\n",
    "        x_train_img[i] = np.load(p)[\"img\"]\n",
    "# no normalize for training images, since they will be augmented and normalized during training\n",
    "\n",
    "# load test images\n",
    "x_test_img = np.zeros((len(x_test_img_path), 299,299,3))\n",
    "for i,p in enumerate(x_test_img_path):\n",
    "    if p is not None:\n",
    "        x_test_img[i] = np.load(p)[\"img\"]\n",
    "# normalize\n",
    "x_test_img = x_test_img.astype('float32')\n",
    "x_test_img /= 255\n",
    "\n",
    "print(x_train_img.shape, x_test_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7523cf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change wave data to mel-stft\n",
    "def calculate_melsp(x, n_fft=1024, hop_length=128):\n",
    "    stft = np.abs(librosa.stft(x, n_fft=n_fft, hop_length=hop_length))**2\n",
    "    log_stft = librosa.power_to_db(stft)\n",
    "    melsp = librosa.feature.melspectrogram(S=log_stft,n_mels=128)\n",
    "    return melsp\n",
    "\n",
    "# load a wave data\n",
    "def load_wave_data(filepath):\n",
    "    x, _ = librosa.load(filepath, sr=44100)\n",
    "    return x,_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fbb226",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_snd_path = dataset_train[\"snd\"].values\n",
    "x_test_snd_path = dataset_test[\"snd\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddeeb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = 128\n",
    "time = 1723\n",
    "\n",
    "# load test sounds\n",
    "x_test_snd = np.zeros((len(x_test_snd_path), freq,time))\n",
    "for i,p in enumerate(x_test_snd_path):\n",
    "    if p is not None:\n",
    "        s,_ = load_wave_data(p)\n",
    "        x_test_snd[i] = calculate_melsp(s)\n",
    "    \n",
    "x_test_snd = x_test_snd.reshape(len(x_test_snd), freq,time, 1)\n",
    "print(x_test_snd.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10a465e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert Japanese characters to unicode\n",
    "# delete a character randomly with del_rate \n",
    "def convert_text_to_unicode(s,del_rate=0.001):\n",
    "    if s == 0:\n",
    "        return [0]\n",
    "    else:\n",
    "        return [ord(x) for  x in str(s).strip() if random.random() > del_rate]\n",
    "\n",
    "def reshape_text(s, max_length=200,del_rate=0.001):\n",
    "    s_ = convert_text_to_unicode(s,del_rate=del_rate)\n",
    "    s_ = s_[:max_length]\n",
    "    if len(s_) < max_length:\n",
    "        s_ += ([0] * (max_length - len(s_)))\n",
    "    return s_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b4eb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_length = 200\n",
    "\n",
    "# load texts\n",
    "x_train_text = dataset_train[\"text\"].values\n",
    "x_test_text = np.array([reshape_text(t, max_length=txt_length,del_rate=0) for t in dataset_test[\"text\"].values])\n",
    "print(x_train_text.shape, x_test_text.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891698b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = dataset_train[\"target\"].values\n",
    "y_test = dataset_test[\"target\"].values\n",
    "\n",
    "y_train = utils.to_categorical(y_train)\n",
    "y_test = utils.to_categorical(y_test)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698cad9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc15c2bb",
   "metadata": {},
   "source": [
    "## 4. モデルを定義する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13475cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import backend as K\n",
    "from keras import Model, Input\n",
    "from keras.layers import Dense,GlobalAveragePooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from keras.models import save_model, load_model\n",
    "from keras.layers import Activation, Dropout, AlphaDropout, Conv1D, Conv2D, Reshape, Lambda\n",
    "from keras.layers import GlobalMaxPooling1D, MaxPool2D, MaxPool1D, GlobalMaxPooling2D\n",
    "from keras.layers import BatchNormalization, Embedding, Concatenate, Maximum,Add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7ae1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# character level cnn for text feature extraction\n",
    "input_text = Input(shape=(txt_length,), name='input_text')\n",
    "def clcnn(input_text):\n",
    "    filter_sizes = (2,3,4,5)\n",
    "\n",
    "    clx = Embedding(0xffff, 256, name='clx_emb')(input_text)\n",
    "    convs = []\n",
    "    for i in range(len(filter_sizes)):\n",
    "        _clx = Conv1D(filters=256, kernel_size=filter_sizes[i], \n",
    "                      strides=(filter_sizes[i]//2), padding=\"same\",\n",
    "                      name='clx_conv1d_{0}'.format(str(i)))(clx)\n",
    "        _clx = Activation(\"tanh\",\n",
    "                      name='clx_act1_{0}'.format(str(i)))(_clx)\n",
    "        _clx = GlobalMaxPooling1D(name='clx_gmp1d_{0}'.format(str(i)))(_clx)\n",
    "        convs.append(_clx)\n",
    "    clx = Concatenate(name='clx_concat')(convs)\n",
    "    clx = Dense(1024, activation=\"selu\",  kernel_initializer=\"lecun_normal\", name=\"clx_selu_0\")(clx)\n",
    "    clx = Dropout(0.1, name=\"clx_dr_0\")(clx)\n",
    "    clx = Dense(256, activation=\"selu\", kernel_initializer=\"lecun_normal\", name=\"clx_selu_1\")(clx)\n",
    "    return clx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365aa9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xception for image feature extraction\n",
    "input_img = Input(shape=(299, 299, 3), name=\"input_tensor\")\n",
    "def xception(input_img):\n",
    "    cnn = keras.applications.Xception(input_tensor=input_img, include_top=False, weights='imagenet')\n",
    "    xcp = cnn.output\n",
    "    xcp = GlobalAveragePooling2D(name=\"xcp_gap2d\")(xcp)\n",
    "    xcp = Dense(256, activation='relu', name=\"xcp_dense_relu\")(xcp)\n",
    "    return xcp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b489a7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn for sound feature extraction\n",
    "input_snd = Input(shape=(freq, time, 1), name=\"input_snd\")\n",
    "def snd_cnn(input_snd):\n",
    "    freq = 128\n",
    "    time = 1723\n",
    "    def cba(inputs, filters, kernel_size, strides, name):\n",
    "        x = Conv2D(filters, kernel_size=kernel_size, strides=strides, padding='same', name=\"snd_conv_{0}\".format(name))(inputs)\n",
    "        x = BatchNormalization(name=\"snd_bn_{0}\".format(name))(x)\n",
    "        x = Activation(\"relu\", name=\"snd_relu_{0}\".format(name))(x)\n",
    "        return x\n",
    "\n",
    "    x_1 = cba(input_snd, filters=32, kernel_size=(1,8), strides=(1,2), name=\"1_0\")\n",
    "    x_1 = cba(x_1, filters=32, kernel_size=(8,1), strides=(2,1), name=\"1_1\")\n",
    "    x_1 = cba(x_1, filters=64, kernel_size=(1,8), strides=(1,2), name=\"1_2\")\n",
    "    x_1 = cba(x_1, filters=64, kernel_size=(8,1), strides=(2,1), name=\"1_3\")\n",
    "\n",
    "    x_2 = cba(input_snd, filters=32, kernel_size=(1,16), strides=(1,2), name=\"2_0\")\n",
    "    x_2 = cba(x_2, filters=32, kernel_size=(16,1), strides=(2,1), name=\"2_1\")\n",
    "    x_2 = cba(x_2, filters=64, kernel_size=(1,16), strides=(1,2), name=\"2_2\")\n",
    "    x_2 = cba(x_2, filters=64, kernel_size=(16,1), strides=(2,1), name=\"2_3\")\n",
    "\n",
    "    x_3 = cba(input_snd, filters=32, kernel_size=(1,32), strides=(1,2), name=\"3_0\")\n",
    "    x_3 = cba(x_3, filters=32, kernel_size=(32,1), strides=(2,1), name=\"3_1\")\n",
    "    x_3 = cba(x_3, filters=64, kernel_size=(1,32), strides=(1,2), name=\"3_2\")\n",
    "    x_3 = cba(x_3, filters=64, kernel_size=(32,1), strides=(2,1), name=\"3_3\")\n",
    "\n",
    "    x_4 = cba(input_snd, filters=32, kernel_size=(1,64), strides=(1,2), name=\"4_0\")\n",
    "    x_4 = cba(x_4, filters=32, kernel_size=(64,1), strides=(2,1), name=\"4_1\")\n",
    "    x_4 = cba(x_4, filters=64, kernel_size=(1,64), strides=(1,2), name=\"4_2\")\n",
    "    x_4 = cba(x_4, filters=64, kernel_size=(64,1), strides=(2,1), name=\"4_3\")\n",
    "\n",
    "    x_snd = Add(name=\"snd_add\")([x_1, x_2, x_3, x_4])\n",
    "\n",
    "    x_snd = cba(x_snd, filters=128, kernel_size=(1,16), strides=(1,2), name=\"5_0\")\n",
    "    x_snd = cba(x_snd, filters=128, kernel_size=(16,1), strides=(2,1), name=\"5_1\")\n",
    "\n",
    "    x_snd = GlobalAveragePooling2D(name=\"snd_gap\")(x_snd)\n",
    "    snd = Dense(256, activation='relu', name=\"snd_dense\")(x_snd)\n",
    "    return snd\n",
    "\n",
    "clx = clcnn(input_text)\n",
    "xcp = xception(input_img)\n",
    "snd = snd_cnn(input_snd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83489b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# leave only maximum features to eliminate null inputs\n",
    "clxcpsnd = Concatenate()([clx, xcp, snd])\n",
    "clxcpsnd = Dense(256, activation='relu', name=\"last_dense\")(clxcpsnd)\n",
    "\n",
    "# classification layer\n",
    "clxcpsnd = Dropout(0.5)(clxcpsnd)\n",
    "clxcpsnd = Dense(y_train.shape[1], activation='softmax', name=\"softmax\")(clxcpsnd)\n",
    "\n",
    "model = Model([input_text, input_img, input_snd], clxcpsnd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44a4763",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4402d6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimization\n",
    "model.compile(optimizer=Adam(lr=1e-4, decay=1e-6, amsgrad=True),\n",
    "             loss=categorical_crossentropy,\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7780b43d",
   "metadata": {},
   "source": [
    "## 5. 学習する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d488ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data augmentation: add white noise\n",
    "def add_white_noise(x, rate=0.002):\n",
    "    return x + rate*np.random.randn(len(x))\n",
    "\n",
    "# data augmentation: shift sound in timeframe\n",
    "def shift_sound(x, rate=2):\n",
    "    return np.roll(x, int(len(x)//rate))\n",
    "\n",
    "# data augmentation: stretch sound\n",
    "def stretch_sound(x, rate=1.1):\n",
    "    input_length = len(x)\n",
    "    x = librosa.effects.time_stretch(x, rate)\n",
    "    if len(x)>input_length:\n",
    "        return x[:input_length]\n",
    "    else:\n",
    "        return np.pad(x, (0, max(0, input_length - len(x))), \"constant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c30cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random erasing for image\n",
    "def get_random_eraser(p=0.5, s_l=0.02, s_h=0.4, r_1=0.3, r_2=1/0.3, v_l=0, v_h=255):\n",
    "    def eraser(input_img):\n",
    "        img_h, img_w, _ = input_img.shape\n",
    "        p_1 = np.random.rand()\n",
    "\n",
    "        if p_1 > p:\n",
    "            return input_img\n",
    "\n",
    "        while True:\n",
    "            s = np.random.uniform(s_l, s_h) * img_h * img_w\n",
    "            r = np.random.uniform(r_1, r_2)\n",
    "            w = int(np.sqrt(s / r))\n",
    "            h = int(np.sqrt(s * r))\n",
    "            left = np.random.randint(0, img_w)\n",
    "            top = np.random.randint(0, img_h)\n",
    "\n",
    "            if left + w <= img_w and top + h <= img_h:\n",
    "                break\n",
    "\n",
    "        c = np.random.uniform(v_l, v_h)\n",
    "        input_img[top:top + h, left:left + w, :] = c\n",
    "\n",
    "        return input_img\n",
    "\n",
    "    return eraser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f5a524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input data generator for training\n",
    "class MultiModalIterator():\n",
    "    def __init__(self,\n",
    "                 x_train_img,\n",
    "                 x_train_snd_path,\n",
    "                 x_train_text,\n",
    "                 y_train,\n",
    "                 batch_size=8,\n",
    "                 shuffle=True,\n",
    "                 datagen=ImageDataGenerator(\n",
    "                     rotation_range=180,\n",
    "                     width_shift_range=0.2,\n",
    "                     height_shift_range=0.2,\n",
    "                     shear_range=10,\n",
    "                     zoom_range=0.3,\n",
    "                     horizontal_flip=True,\n",
    "                     vertical_flip=True,\n",
    "                     channel_shift_range=5.,\n",
    "                     brightness_range=[0.3, 1.0],\n",
    "                     preprocessing_function=get_random_eraser(v_l=0,\n",
    "                                                              v_h=255))):\n",
    "\n",
    "        self.x_train_img = x_train_img\n",
    "        self.x_train_snd_path = x_train_snd_path\n",
    "        self.x_train_text = x_train_text\n",
    "        self.y_train = y_train\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.sample_num = len(self.y_train)\n",
    "        self.datagen = datagen\n",
    "\n",
    "    def __call__(self):\n",
    "        while True:\n",
    "            indexes = self.__get_exploration_order()\n",
    "            itr_num = int(len(indexes) // (self.batch_size))\n",
    "\n",
    "            for i in range(itr_num):\n",
    "                batch_ids = indexes[i * self.batch_size:(i + 1) * self.batch_size]\n",
    "                x_text, x_img, x_snd, y = self.__data_generation(batch_ids)\n",
    "\n",
    "                yield [x_text, x_img, x_snd], y \n",
    "\n",
    "    def __get_exploration_order(self):\n",
    "        indexes = np.arange(self.sample_num)\n",
    "\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(indexes)\n",
    "\n",
    "        return indexes\n",
    "    \n",
    "    def __load_text(self,batch_ids):\n",
    "        # convert Japanese characters to unicode, with random deletion of del_rate\n",
    "        x_train_text = np.array([reshape_text(t, max_length=txt_length, del_rate=0.001) for t in self.x_train_text[batch_ids]])\n",
    "        return x_train_text\n",
    "    \n",
    "    def __load_snd(self, batch_ids):\n",
    "        # load sound data\n",
    "        x_train_snd = np.zeros((self.batch_size, freq,time))\n",
    "        for i,p in enumerate(self.x_train_snd_path[batch_ids]):\n",
    "            if p is not None:\n",
    "                # load from .wav format\n",
    "                _x,_ = load_wave_data(p)\n",
    "                # randomly add augmentation\n",
    "                if np.random.choice((True,False)):\n",
    "                    # add white noise\n",
    "                    _x = add_white_noise(x=_x, rate=np.random.randint(1,50)/1000)\n",
    "                _t = np.random.choice([0,1,2])\n",
    "                if _t==1:\n",
    "                    # shift sound\n",
    "                    _x = shift_sound(x=_x, rate=np.random.choice(np.arange(2,6)))\n",
    "                elif _t==2:\n",
    "                    # stretch sound\n",
    "                    _x = stretch_sound(x=_x, rate=np.random.choice(np.arange(80,120))/100)\n",
    "                # convert to melsp numpy array\n",
    "                x_train_snd[i] = calculate_melsp(_x)\n",
    "        x_train_snd = x_train_snd.reshape(self.batch_size, freq, time, 1)\n",
    "        return x_train_snd\n",
    "\n",
    "    def __data_generation(self, batch_ids):\n",
    "        x_text = self.__load_text(batch_ids)\n",
    "        \n",
    "        x_img = self.x_train_img[batch_ids]\n",
    "        x_img = x_img.astype('float32')\n",
    "        for i in range(self.batch_size):\n",
    "            x_img[i] = self.datagen.random_transform(x_img[i])\n",
    "            x_img[i] = self.datagen.standardize(x_img[i])\n",
    "        x_img /= 255\n",
    "        \n",
    "        x_snd = self.__load_snd(batch_ids)\n",
    "        \n",
    "        y = self.y_train[batch_ids]\n",
    "\n",
    "        return x_text, x_img, x_snd, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf91ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "epochs = 1\n",
    "\n",
    "training_iterator = MultiModalIterator(\n",
    "    x_train_img,\n",
    "    x_train_snd_path,\n",
    "    x_train_text,\n",
    "    y_train, \n",
    "    batch_size=batch_size)()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a6869d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \".\\\\model\\\\\"\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "chkpt = os.path.join(model_dir, 'multimodal.{epoch:02d}_{loss:.4f}_{val_loss:.4f}.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15873671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "model.fit_generator(\n",
    "        training_iterator,\n",
    "        steps_per_epoch=len(y_train)//batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=([x_test_text, x_test_img, x_test_snd], y_test),\n",
    "        workers=6,\n",
    "        #use_multiprocessing=True,\n",
    "        pickle_safe=False, # 追加\n",
    "        callbacks=[EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='auto'),\n",
    "                    ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, verbose=1, min_lr=1e-8),\n",
    "                    ModelCheckpoint(filepath = chkpt, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84ba0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/keras-team/keras/issues/3962"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7f22e3",
   "metadata": {},
   "source": [
    "# 6. 評価する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05dc90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy, precision, recall, and f1-score\n",
    "y_preds = model.predict([x_test_text, x_test_img, x_test_snd])\n",
    "y_pred_ = np.argmax(y_preds, axis =1)\n",
    "y_test_ = np.argmax(y_test, axis=1)\n",
    "\n",
    "print(accuracy_score(y_test_, y_pred_))\n",
    "print(classification_report(y_test_, y_pred_))\n",
    "print(confusion_matrix(y_test_, y_pred_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a595bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
